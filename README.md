
# Be Greedy in Multi-Armed Bandits

This repository contains the companion code for the following [paper](https://arxiv.org/abs/2101.01086):

M. Jedor, J. LouÃ«dec and V. Perchet. Be Greedy in Multi-Armed Bandits. arXiv preprint arXiv:2101.01086, 2021.

## Implementation

In addition to the code reproducing the numerical experiments of the aforementioned paper, this repository contains a functional implementation of several bandit models along with state-of-the-art algorithms. Specifically, the following bandit models are implemented:

- Multi-armed bandits
- Bayesian multi-armed bandits
- Continuous-armed bandits
- Infinite-armed bandits
- Linear bandits
- Mortal bandits
- Budgeted bandits
- Cascading bandits

## Installation

This code is compatible with Python 3. 

The primary dependencies are:

* [Matplotlib](https://matplotlib.org/)
* [Numpy](https://numpy.org/)  
* [Scipy](https://www.scipy.org/)

## License

This code has a MIT license.
